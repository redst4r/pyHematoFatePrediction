{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import movieTools.config\n",
    "import movieTools.imageNormalizer as imageNormalizer\n",
    "from movieTools.movie import Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "import bokeh.plotting as bp # figure, show, output_file\n",
    "output_notebook()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from talk_plottingutils import plot_image_mpl, plot_image_rgb_bokeh, plot_image_bokeh, \\\n",
    "                               hv_plot_stack, plot_segmentation_bokeh, plot_segmentation, normalize01\n",
    "from talk_utils import tile_raster_images\n",
    "\n",
    "\n",
    "# skimage\n",
    "from skimage.morphology import closing, opening, disk, dilation, watershed, local_maxima\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import find_boundaries, mark_boundaries\n",
    "from scipy.ndimage.morphology import binary_fill_holes, distance_transform_edt\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import toolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "![Segmentation](images/segmentation/segmentation.png)\n",
    "\n",
    "**Steps**:\n",
    "1. separate background and foreground: **MSER**\n",
    "![MSER](images/segmentation/mser.png)\n",
    "\n",
    "2. split clumped objects: **Watershed** ![Segmentation](images/segmentation/watershed.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieTools.config.TTTDIR = '/home/michi/pythonProjects/deepLearning/Hemato_korea/data_small/'\n",
    "movie = Movie('experiment3', verbose=False)  # 140206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading a single image from disk and transforming to unit8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint = 3355\n",
    "position = 54\n",
    "I = movie.loadimage(position, timepoint, WL='w00', extension='png', normalizer=imageNormalizer.BaSiC_Normalizer())\n",
    "\n",
    "def raw_transform(I):\n",
    "    \"scales it into [0,255] and transofrms into uint8\"\n",
    "    I = I - I.min()\n",
    "    I = I/I.max()\n",
    "    I = (I*2**8).astype('uint8')\n",
    "    return I\n",
    "\n",
    "I = raw_transform(I)\n",
    "\n",
    "plot_image_bokeh(I);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mser = cv2.MSER_create()\n",
    "\n",
    "# MSER has a few parameters to be set\n",
    "mser_delta = 4\n",
    "mser_min = 20    # min size of object\n",
    "mser_max = 4000  # max size of object\n",
    "\n",
    "mser.setDelta(mser_delta)\n",
    "mser.setMinArea(mser_min)\n",
    "mser.setMaxArea(mser_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect **MSER-regions** and put them into a binary FG/BG **mask**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions2mask(regions, ishape):\n",
    "    \"turns a list of pixel coordinates into a binary image mask\"\n",
    "    bw = np.zeros(ishape)\n",
    "    for r in regions:\n",
    "        for i in range(len(r)): \n",
    "            bw[r[i,1], r[i,0]] = 1  # the usual row/col/x/y switch\n",
    "    return bw\n",
    "\n",
    "regions = mser.detectRegions(I, None)\n",
    "seg_mask = regions2mask(regions, I.shape)\n",
    "plot_segmentation_bokeh(I, seg_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some postprocessing of the segmentation mask:\n",
    "- Closing\n",
    "- Hole fill\n",
    "- Opening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mser_postprocess(seg_mask):\n",
    "    \"morphological operations to enhacne the segmentation\"\n",
    "    bw_closed = closing(seg_mask, disk(2))\n",
    "    # TODO brige operation missing\n",
    "    filled_bw = binary_fill_holes(bw_closed)\n",
    "    opened_bw = opening(filled_bw, disk(2))\n",
    "    return opened_bw\n",
    "\n",
    "opened_bw = mser_postprocess(seg_mask)\n",
    "# plot_segmentation(I, opened_bw)\n",
    "plot_segmentation_bokeh(I, opened_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershedding\n",
    "to split merged objects.\n",
    "\n",
    "1. find initial centers of cells\n",
    "2. watershedding starting from the centers\n",
    "<img src=\"images/segmentation/watershed_scetch.png\" alt=\"Watershedding\" style=\"width: 600px;\" title=\"http://www.mdpi.com/2072-4292/6/1/776/htm\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding seeds for the watershed\n",
    "i.e. locate the centers of the forground objects\n",
    "- **distance transform**: distance of each pixel to the next background pixel\n",
    "- more sophisticated: Circular **Hough transform** (not implemented here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_transform = cv2.distanceTransform(opened_bw.astype('uint8'),cv2.DIST_L2,5)\n",
    "plot_segmentation_bokeh(I, normalize01(dist_transform))\n",
    "\n",
    "# plt.figure(figsize=(30,30))\n",
    "# plot_segmentation(I, dist_transform); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look for local maxima in he distance transform** to get pixels in the center of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sure_fg = local_maxima(dist_transform)\n",
    "sure_fg = dilation(sure_fg, disk(1))  # enlarge these single pixel centers, merging nearby maxima\n",
    "plot_segmentation_bokeh(I, sure_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual watershed\n",
    "finds the border between adjacent cell centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute_labels(marked_img):\n",
    "    \"\"\"\n",
    "    given a labeled segmentation mask (each object has its unique integer in the mask)\n",
    "    randomize the labeling. ACtually just useful for visualization, giving different color to neighbouring objects\n",
    "    \"\"\"\n",
    "    M = np.unique(marked_img)\n",
    "    # kick out zeros as this marks background\n",
    "    M = M[M!=0]\n",
    "    N = np.random.choice(M, size=len(M),replace=False) \n",
    "    new_marks = np.zeros(marked_img.shape)\n",
    "    \n",
    "    for i, m in enumerate(M):\n",
    "        new_label = N[i]\n",
    "        new_marks+= np.full(marked_img.shape, new_label) * (marked_img==m)\n",
    "    return new_marks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = label(sure_fg)\n",
    "markers = permute_labels(markers)  # just for visualization to mix colors\n",
    "\n",
    "# plt.figure(figsize=(20,20)); plt.imshow(markers, cmap=plt.cm.nipy_spectral); plt.grid();plt.show()\n",
    "plot_image_bokeh(markers, cmap='RdGy11');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_ws = watershed(-dist_transform, markers, mask=opened_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_bokeh(labels_ws, cmap='RdGy11');\n",
    "# plt.figure(figsize=(20,20)); plt.imshow(labels_ws, cmap=plt.cm.nipy_spectral); plt.grid();plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filter** out obvious non-cell objects:\n",
    "- non-round \n",
    "- too large/small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area, ecc = zip(*[(r.area, r.eccentricity) \n",
    "                  for r in regionprops(labels_ws, intensity_image=None, cache=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(area, ecc)\n",
    "plt.xlabel('area')\n",
    "plt.ylabel('eccentricity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_segObjects(labels_ws):\n",
    "\n",
    "    #labels_ws: segmentation mask, each object with a different integer\n",
    "    \n",
    "    eccfilter = 0.99;\n",
    "    ecccombfilter = 0.7;\n",
    "    maxsizecombfilter = 700;\n",
    "    minsize = 40;\n",
    "    maxsize = 1000;\n",
    "    \n",
    "    filtered = np.zeros(labels_ws.shape, dtype=np.bool)\n",
    "    for r in regionprops(labels_ws, intensity_image=None, cache=True):\n",
    "        if not minsize < r.area < maxsize \\\n",
    "            or r.eccentricity >  eccfilter\\\n",
    "            or (r.eccentricity>ecccombfilter and r.area>maxsizecombfilter):\n",
    "\n",
    "            filtered[labels_ws==r.label]= 1\n",
    "    # masks out the filtered objects in the segmentation mask\n",
    "    labels_ws = labels_ws * (1-filtered)\n",
    "    return labels_ws\n",
    "\n",
    "labels_ws_filtered = filter_segObjects(labels_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(labels_ws_filtered, cmap=plt.cm.nipy_spectral)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate the objects in the segmentation mask\n",
    "even though we know the individual cells no, let's split them in the segmentation mask, i.e. delete the boundary pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_objects(labels_ws):\n",
    "    \"separates segmented objects that touch each other, ie setting their border to background\"\n",
    "    outer_bound = find_boundaries(labels_ws, mode='outer')\n",
    "    touching_object_pixels = outer_bound * opened_bw\n",
    "\n",
    "    # set these touching pixels to background in the segmantation mask (so that the obejcts are distinct)\n",
    "    final_segmentation = labels_ws > 0\n",
    "    final_segmentation[touching_object_pixels==True] = 0\n",
    "    return final_segmentation\n",
    "\n",
    "final_segmentation = separate_objects(labels_ws_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_segmentation(I, final_segmentation); plt.show()\n",
    "plot_segmentation_bokeh(I, final_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch extraction\n",
    "extract 27x27 image patches around the segmentation centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(bw_segmentation, I0):\n",
    "    centers = [np.ceil(_.centroid).astype('int')\n",
    "                        for _ in regionprops(label(bw_segmentation), intensity_image=None, cache=True)]\n",
    "    patches = []\n",
    "    for y, x in centers:\n",
    "        \n",
    "        #annoying detail: sometimes the center is to close to the image-edge\n",
    "        # lets just skip these images\n",
    "        the_patch = I0[y-13:y+13, x-13:x+13]\n",
    "        if not the_patch.shape == (26,26):\n",
    "            continue\n",
    "        patches.append(the_patch.astype('float'))\n",
    "    return np.stack(patches)\n",
    "\n",
    "patches = extract_patches(final_segmentation, I)\n",
    "tile_raster_images(patches, img_dim=(1,2), tile_shape=(5,7))\n",
    "plt.grid(False); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     24
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VERBOSE= False\n",
    "def applyMSER(I):\n",
    "    mser = cv2.MSER_create()\n",
    "\n",
    "    # MSER has a few parameters to be set\n",
    "    mser_delta = 4\n",
    "    mser_min = 20\n",
    "    mser_max = 4000\n",
    "    mser.setDelta(mser_delta)\n",
    "    mser.setMinArea(mser_min)\n",
    "    mser.setMaxArea(mser_max)\n",
    "    regions = mser.detectRegions(I, None)\n",
    "    seg_mask = regions2mask(regions, I.shape)\n",
    "    opened_bw = mser_postprocess(seg_mask)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        plot_segmentation_bokeh(raw_transform(I), opened_bw)\n",
    "    return opened_bw\n",
    "\n",
    "def applyWatershed(bw_segmentation_mask):\n",
    "    # bw_segmentation_mask: a binary segmentation mask\n",
    "    dist_transform = cv2.distanceTransform(bw_segmentation_mask.astype('uint8'),cv2.DIST_L2,5)\n",
    "\n",
    "    sure_fg = local_maxima(dist_transform)\n",
    "    sure_fg = dilation(sure_fg, disk(1))\n",
    "    if VERBOSE:\n",
    "        plot_segmentation_bokeh(sure_fg, sure_fg)\n",
    "   \n",
    "    markers = label(sure_fg)\n",
    "    labels_ws = watershed(-dist_transform, markers, mask=bw_segmentation_mask)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        plot_segmentation_bokeh(I, labels_ws)\n",
    "\n",
    "    return labels_ws\n",
    "\n",
    "segmentation_function = toolz.compose(separate_objects, filter_segObjects, applyWatershed, applyMSER,raw_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "I0 = movie.loadimage(position, timepoint, WL='w00', extension='png', normalizer=imageNormalizer.BaSiC_Normalizer())\n",
    "final_segmentation = segmentation_function(I0)\n",
    "plot_segmentation_bokeh(raw_transform(I0), final_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading preexisting segmentation\n",
    "Let's use a more sophisticated existing segmentation [`Buggenthin et al.`] for some further analysis.\n",
    "Here, the entire movie is segmented, and we can get the segmentation/image patches as well as some features of these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all segmented objects from a time/position\n",
    "properties, images, cropped_flag = movie.get_segmented_objects_from_images(timepoint, position)\n",
    "\n",
    "print(properties[1]) # properies of the first segmented object\n",
    "plt.imshow(images[1], cmap=plt.cm.Greys_r); plt.grid(False); plt.show() # image of that cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets compare to our segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_objs_centroids = [(info['x'], info['y']) \n",
    "                      for info in movie.get_segmented_objects_from_images(timepoint, position)[0]]\n",
    "seg_objs_centroids = np.array(seg_objs_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_bokeh(I, points=seg_objs_centroids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation_bokeh(I, segmentation_function(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell numbers over time\n",
    "Looking at the number of segmented objects over time in the two positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 3300,3400\n",
    "\n",
    "plt.figure()\n",
    "for pos in [54,55]:\n",
    "    prop_generator = (movie.get_segmented_objects_from_images(timepoint=_, position=pos)[0] \n",
    "                      for _ in range(tmin,tmax))\n",
    "    Q = toolz.concat(prop_generator)\n",
    "    timepoints = toolz.pluck('timepoint', Q)\n",
    "    timepoint_histogram = toolz.frequencies(timepoints)\n",
    "    t, freq = list(zip(*timepoint_histogram.items()))\n",
    "    plt.plot(t,freq)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('#cells')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell locations over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_generator = (movie.get_segmented_objects_from_images(timepoint=_, position=54)[0] for _ in range(tmin,tmax))\n",
    "Q = toolz.concat(prop_generator)\n",
    "xyta = toolz.pluck(['x','y','timepoint', 'area'], Q)\n",
    "x,y,t, a = zip(*xyta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(x,y,c=t, s=np.array(a)*0.1, cmap=plt.cm.viridis)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_generator = (np.stack(movie.get_segmented_objects_from_images(timepoint=_, position=55)[1]) for _ in range(tmin,tmax))\n",
    "cell_imgs = np.concatenate(list(img_generator), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_raster_images(cell_imgs, img_dim=(1,2), tile_shape=(60,60), figsize=(30,30))\n",
    "plt.grid(False);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "4",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
