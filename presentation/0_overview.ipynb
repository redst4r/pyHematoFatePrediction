{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "- **Bioimage Informatics**\n",
    "    - Background correction: [Notebook](1_background_correction.ipynb)\n",
    "    - Segmentation: [Notebook](2_segmentation.ipynb)\n",
    "    \n",
    "    \n",
    "- **Interlude: Deep learning**\n",
    "    - Logistic regression: [Notebook](3_logistic_regression.ipynb) \n",
    "    - Multilayer perceptron: [Notebook](4_MLP.ipynb)\n",
    "  \n",
    " \n",
    "- **Cell fate prediction in hematopoietic stem cells**\n",
    "    - [Notebook](5_HematoCNN.ipynb) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data\n",
    "I'd *recommend* starting with the smaller dataset first:\n",
    "- **Small dataset** (250MB download), : [Link](https://drive.google.com/file/d/0B_1VCeDlXJH8dmthQ2VZMU9iUDA)\n",
    "\n",
    "If you feel adventurous, here's a larger dataset, containing alot more raw image data and the entire extracted cell patches from the entire experiment\n",
    "- **Large dataset** (2GB download): [Link](https://drive.google.com/open?id=0B_1VCeDlXJH8bWNqdGpTOFJzR3M)\n",
    "\n",
    "Extract into '../' (parent folder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34mdata\u001b[0m/           \u001b[1;35mdata.zip\u001b[0m                    \u001b[32mREADME.md\u001b[0m\r\n",
      "\u001b[34mdata_original\u001b[0m/  \u001b[00mgitattributes_old\u001b[0m           \u001b[00mretrained_hemato_net.h5\u001b[0m\r\n",
      "\u001b[34mdata_small\u001b[0m/     \u001b[34mpresentation\u001b[0m/\r\n",
      "\u001b[1;35mdata_small.zip\u001b[0m  \u001b[00mpretrained_hemato_net.hdf5\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%ls .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial data\n",
    "- If you only want the raw images: [Small dataset](https://drive.google.com/open?id=0B_1VCeDlXJH8LVBOU3drRG8wdk0) (160MB)\n",
    "- only the files needed for the machine learning part: [Small dataset](https://drive.google.com/open?id=0B_1VCeDlXJH8UEpXc0xPM3YtbnM) (90MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setup python\n",
    "The entire code is python based and has various dependencies on external libraries. \n",
    "\n",
    "Here's a quick guide how to set it up. First, get anaconda/miniconda, which is extremly convenient for installing most of these packages.\n",
    "\n",
    "## Anaconda/Miniconda\n",
    "https://conda.io/miniconda.html\n",
    "\n",
    "A very convenient python distribution / package manager. Definitely recommended over preinstalled systemwide python distributions\n",
    "\n",
    "### Linux/Mac\n",
    "\n",
    "- [download](https://conda.io/miniconda.html), run installer and do\n",
    "\n",
    "        source install_location/miniconda3/bin/activate\n",
    "    \n",
    "- create a virtual environment\n",
    "\n",
    "        conda create --name py36_keras python=3.6\n",
    "\n",
    "- activate it via \n",
    "\n",
    "        source activate py36_keras\n",
    "        \n",
    "- install a few packages \n",
    "\n",
    "        conda install nomkl pandas matplotlib bokeh holoviews numpy toolz scikit-image scikit-learn h5py  jupyter beautifulsoup4\n",
    "\n",
    "    \n",
    "### Windows\n",
    "(tested on Windows 7)\n",
    "- [download](https://conda.io/miniconda.html), run installer, open the \"Anaconda Prompt\"\n",
    "\n",
    "- create a virtual environment\n",
    "\n",
    "        conda create --name py36_keras python=3.6\n",
    "- activate it \n",
    "\n",
    "        activate py36_keras\n",
    "\n",
    "- install a few packages\n",
    "\n",
    "        conda install pandas matplotlib bokeh holoviews numpy toolz scikit-image scikit-learn h5py jupyter beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Anaconda Cloud:\n",
    "Get my conda environment from Anaconda Cloud:\n",
    "\n",
    "\n",
    "    conda env create redst4r/py36_keras\n",
    "    source activate py36_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV\n",
    "Library for image processing. Only needed here for its MSER implementation\n",
    "\n",
    "### Linux/Mac\n",
    "\n",
    "    conda install opencv\n",
    "\n",
    "### Windows\n",
    "\n",
    "- download `opencv_python‑3.3.0‑cp36‑cp36m‑win_amd64.whl` from http://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv\n",
    "- cd into containing folder, do\n",
    "\n",
    "        pip install opencv_python‑3.3.0‑cp36‑cp36m‑win_amd64.whl\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## movieTools:\n",
    "Library to handle time lapse microscopy\n",
    "\n",
    "- with **git** available\n",
    "\n",
    "        pip install -e git+https://github.com/redst4r/movieTools.git#egg=movieTools-0.1\n",
    "        \n",
    "- **no git**: download from https://github.com/redst4r/movieTools, cd into folder, do \n",
    "    \n",
    "            pip install .\n",
    "\n",
    "---\n",
    "\n",
    "## Tensorflow\n",
    "Machine learning Library, mostly used for neural nets\n",
    "- [tensorflow howto](https://www.tensorflow.org/install/)\n",
    "\n",
    "### Linux\n",
    "    pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "            \n",
    "### Mac\n",
    "    pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl\n",
    "            \n",
    "### Windows:\n",
    "    pip install --ignore-installed --upgrade tensorflow \n",
    "\n",
    "---\n",
    "\n",
    "## Keras\n",
    "https://keras.io/#installation\n",
    "\n",
    "A very convenient high level wrapper around tensorflow (and other DL-libraries)\n",
    "\n",
    "     pip install keras\n",
    "     \n",
    "# Jupyter Notebook Server\n",
    "fire up the notebook server via\n",
    "\n",
    "    jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "    \n",
    "(the `iopub_data_rate_limit` argument allows more data to be shown in the notebooks, needed form segmentation/background correction notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "4",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
