{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN for cell fate classification of hematopoietic stem cells\n",
    "\n",
    "A short tutorial/redo of the analysis done in the following paper: \n",
    "\n",
    "[Prospective identification of hematopoietic lineage choice by deep learning](http://www.nature.com/nmeth/journal/v14/n4/full/nmeth.4182.html)    \n",
    "Felix Buggenthin, Florian Buettner, Philipp S Hoppe, Max Endele, Manuel Kroiss, Michael Strasser, Michael Schwarzfischer, Dirk Loeffler, Konstantinos D Kokkaliaris, Oliver Hilsenbeck, Timm Schroeder, Fabian J Theis, Carsten Marr; *Nature Methods 14, 403â€“406* (2017)\n",
    "\n",
    "\n",
    "[Code](https://github.com/QSCD/HematoFatePrediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from talk_utils import tile_raster_images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the CNN in  keras\n",
    "- Conv1 / Maxpool1\n",
    "- Conv2 / Maxpool2\n",
    "- Conv3 / Maxpool3\n",
    "- merge with speed\n",
    "- fc6\n",
    "- fc7\n",
    "- fc8/softmax\n",
    "\n",
    "![HematoCNN](images/hemato_cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from talk_hemato_utils import create_hemato_cnn\n",
    "CNN = create_hemato_cnn()\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the pretrained weights onto the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe2keras_conversion\n",
    "CNN = caffe2keras_conversion.load_weights_caffe2keras('../pretrained_hemato_net.hdf5', CNN, bn_trainable=True, other_param_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the retrained weights and the corresponding data\n",
    "Turns out that the pretrained weights are hard to transfer to keras (Batch normalization etc). Hence, I retrained the network on a subset of the data provided in `images_round3_test_annotated.pickle`. \n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n",
    "\n",
    "**Note**: This is **VERY different** from the \"across-movie\" training/prediction done in the original paper.\n",
    "I instead train and evaluate on the same experiment here (samples in train/testset are still disjunct, but come from the same experiment).\n",
    "Therefore the results in this notebook are **overoptimistic**. But this notebook serves for demonstration only anyways :)\n",
    "![roundRobin](images/roundrobin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CNN.load_weights('../retrained_hemato_net.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the exact same datasplit I used from training, such that our testset is different from the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "FULL_ANNOTATED = False \n",
    "\n",
    "if FULL_ANNOTATED:  # load the full annotation data. careful, 1GB on disc\n",
    "    with open('../data/retrained_datasplit.pickle', 'rb') as fh:\n",
    "        X_train,X_val,X_test,\\\n",
    "        y_train,y_val,y_test,\\\n",
    "        mov_train, mov_val, mov_test,\\\n",
    "        cell_train, cell_val, cell_test = pickle.load(fh)\n",
    "    \n",
    "    print(\" %d train data\\n %d val. data\\n %d test data\" % (len(X_train), len(X_val), len(X_test)))\n",
    "\n",
    "    # for fast computation, restrict to just 10000 test-samples\n",
    "    X_test   = X_test[:10000]\n",
    "    y_test   = y_test[:10000]\n",
    "    mov_test = mov_test[:10000]\n",
    "    cell_test= cell_test[:10000]\n",
    "\n",
    "# load a smaller subset of the testset\n",
    "else:\n",
    "    with open('../data_small/small_retrained_datasplit.pickle', 'rb') as fh:\n",
    "        X_test, y_test, mov_test, cell_test = pickle.load(fh)\n",
    "\n",
    "print('loaded a testset of %d samples, containing %d cells' % (len(X_test), len(np.unique(cell_test)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first look at the data\n",
    "Let's look at a few examples of the two classes; \n",
    "- they look very similar to non-experts\n",
    "- sometimes differentiated cells can be observed, which are distinct (e.g. megakaryocytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_class0 = X_test[y_test[:,1]==0]\n",
    "X_class1 = X_test[y_test[:,1]==1]\n",
    "\n",
    "tile_raster_images(X_class0[:1000,:,:,0], img_dim=(1,2), \n",
    "                   tile_shape=(20,50), scale_rows_to_unit_interval=False, figsize=(20,20))\n",
    "\n",
    "tile_raster_images(X_class1[:1000,:,:,0], img_dim=(1,2), \n",
    "                   tile_shape=(20,50), scale_rows_to_unit_interval=False, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in addition we have the movement speed as a feature. Note that speed was already standardized (mean=0, std=1), hence the negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mov_test[y_test[:,1]==0], bins = np.linspace(-1,10,100), histtype='step', normed=True);\n",
    "plt.hist(mov_test[y_test[:,1]==1], bins = np.linspace(-1,10,100), histtype='step', normed=True);\n",
    "plt.xlabel('Movement speed')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.legend(['Class1', 'Class2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Also compare the two classes in terms of their average intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/hemato-01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of annotated cells\n",
    "\n",
    "\n",
    "\n",
    "## Single image prediction\n",
    "\n",
    "**Task 2**\n",
    "- Predict all samples from the testset (takes ~10sec) \n",
    "- look at the histogram of the scores.\n",
    "- what is the accuracy/confusion matrix\n",
    "- what is the area under the ROC curve\n",
    "\n",
    "**Hints**:\n",
    "- `.predict()`\n",
    "- the model has two inputs, the image and speed. Feed them into the model as a list.\n",
    "- `sklearn.metrics` has implementations of confusion/AUC already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/hemato-02.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate cells over multiple timepoints\n",
    "So far, we predict a class for each single cell patch. However, through tracking, we can pool over image patches that belong to the same cell. That should make the classification more robust.\n",
    "\n",
    "<img src=\"images/lineage_Score_over_time.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There's a couple of ways to aggregate:\n",
    "- **hard voting**: each sample is first classified (into 0,1) and then we take the average: I.e 80% of the samples of the cell were classified as 1 -> vote for class 1 \n",
    "- **soft voting**: we could also first average the class scores of all samples of the same cell, then discretize into [0,1]\n",
    "\n",
    "- use a **neural network** to do the aggregation. [Buggenthin et al.] use a RNN to also incorporate the time dependence of the images. (We skip this for simplicity)\n",
    "\n",
    "\n",
    "**Note**: We're somewhat cheating here: The train/val/test split was agnostic of the image patches being linked together. For example, cell 1 could have 10 patches in the training set, and 20 patches in the test set -> **some leakage from training to test** if the patches are strongly correlated and our results are overoptimistic. \n",
    "\n",
    "In [Buggenthin et al.], the training/validation/testsets are **different experiments** to avoid this and similar issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellid = cell_test[1]\n",
    "plt.plot(yhat[cell_test==cellid, 1]);  # plot all predictions belonging to cell xxx\n",
    "plt.xlabel('image patch')\n",
    "plt.ylabel('lineage score')\n",
    "plt.title('Cell %d with true label %d' % (cellid, y_test[cell_test==cellid,1][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas aggregation magic\n",
    "Let's aggregate the different samples using pandas. \n",
    "First put our data (cellid, true labels and predictions into a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([y_test, yhat, cell_test[:,np.newaxis]]), \n",
    "                  columns=['y0', 'y1', 'score0', 'score1', 'cellid'])\n",
    "df['yhat'] = (df['score1'] > 0.5).values.astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group the samples by cellid, calculate the mean of each group (very similar to SQL's `GROUP BY`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr = df.groupby('cellid').mean()\n",
    "aggr = aggr.rename(columns={'score1': 'softvote', 'yhat': 'hardvote'}) \n",
    "aggr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to comply with the usual two column scores\n",
    "softvoted_yhat = np.vstack([1-aggr['softvote'], aggr['softvote']]).T\n",
    "hardvoted_yhat = np.vstack([1-aggr['hardvote'], aggr['hardvote']]).T\n",
    "voted_y = np.vstack([aggr['y0'], aggr['y1']]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "putting that all together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_cell_scores(df):\n",
    "    \"aggregates all scores from the same cell, doing either soft or hard voting\"\n",
    "    df['yhat'] = (df['score1'] > 0.5).values.astype('int')\n",
    "    aggr = df.groupby('cellid').mean()\n",
    "    aggr = aggr.rename(columns={'score1': 'softvote1', 'yhat': 'hardvote1'})\n",
    "    aggr['softvote0'] = 1-aggr['softvote1']\n",
    "    aggr['hardvote0'] = 1-aggr['hardvote1']\n",
    "\n",
    "    return aggr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr = aggregate_cell_scores(df)\n",
    "aggr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(aggr[['softvote0', 'softvote1']].values,  \n",
    "                      aggr[['y0', 'y1']].values, \n",
    "                      classes=[0,1]);\n",
    "\n",
    "get_auc(aggr['softvote1'].values, aggr['y1'], do_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(aggr[['hardvote0', 'hardvote1']].values,  \n",
    "                      aggr[['y0', 'y1']].values, \n",
    "                      classes=[0,1]);\n",
    "\n",
    "get_auc(aggr['hardvote1'].values, aggr['y1'], do_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the CNN to \"latent\" cells\n",
    "So far, we trained the NN on cells that expressed some cell fate markers (hence they were already differentiated).\n",
    "The most important contribution of [Buggenthin et al.] is that this classifier can also be applied to cells expressing no marker yet (latent), and still correctly predict what will happen in the future (we know the future via tracking)\n",
    "\n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small dataset, containing only 100 cells\n",
    "dataset_fname = '../data_small/small_images_round3_test_latent_inverted_generations.pickle'  \n",
    "\n",
    "# thats the full dataset, careful, its about 1GB on disc\n",
    "# dataset_fname = '../data/images_round3_test_latent_inverted_generations.pickle' \n",
    "\n",
    "with open(dataset_fname, 'rb') as fh:\n",
    "    X_l, y_l, movement_l, cellIDs_l, gens_l = pickle.load(fh)\n",
    "print(\"%d patches, %d cells in total\" % (len(X_l), len(np.unique(cellIDs_l))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the \"meta\"-data into a pandas dataframe. This will become very handy later, esp. the **inverted generation**, i.e. the position of the cell wrt to marker onset in the tree (inv.gen=-2 means that the cell fate marker will turn on two generations downstream of that cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([y_l, cellIDs_l[:,np.newaxis], gens_l[:,np.newaxis]]), \n",
    "                  columns=['y0', 'y1', 'cellid', 'gens'])\n",
    "df.head()\n",
    "del cellIDs_l, gens_l  # just that we dont use these by accident later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of latent cells\n",
    "Takes 2min on a Quadcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time yhat_l = CNN.predict([X_l, movement_l], batch_size=128, verbose=1)\n",
    "\n",
    "df['score0'] = yhat_l[:,0]  # put the predictions into the dataframe\n",
    "df['score1'] = yhat_l[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation + AUC\n",
    "again, we want to aggregate the scores of patches belonging to the same cell.\n",
    "\n",
    "What's the distribution of patch scores for a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cellid = df.cellid[0]\n",
    "df_cell = df.query(\"cellid==@cellid\")\n",
    "plt.hist(df_cell['score1'],100);\n",
    "plt.title('Cell %d (%d patches) with true label %f' % (cellid, len(df_cell),df_cell.y1.values[0]))\n",
    "plt.xlabel('lineage score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Aggregate the predictions, calculate the AUC and compare to unaggregated AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/hemato-03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check how our predictive performance changes as we move further away from the observed marker onset.\n",
    "However, keep in mind that the further into the past we go, the less cells we have to evaluate the performance on!\n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**: \n",
    "- stratify the samples according to their inverted generation (`df['gens']`)\n",
    "- calculate the AUC. How long before marker onset is their cell fate predictable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/hemato-04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Again, keep in mind that we didnt evaluate on a totally different testset (I trained the classifier on a subset of the \"annotated\" cells in a single experiment). So applying the classifier to \"latent\" cells of the same movie might be **too optimistic** (e.g. overfitting on lighting conditions etc)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "4",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
