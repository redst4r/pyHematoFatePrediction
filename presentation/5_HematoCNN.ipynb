{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN for cell fate classification of hematopoietic stem cells\n",
    "\n",
    "A short tutorial/redo of the analysis done in the following paper: \n",
    "\n",
    "[Prospective identification of hematopoietic lineage choice by deep learning](http://www.nature.com/nmeth/journal/v14/n4/full/nmeth.4182.html)    \n",
    "Felix Buggenthin, Florian Buettner, Philipp S Hoppe, Max Endele, Manuel Kroiss, Michael Strasser, Michael Schwarzfischer, Dirk Loeffler, Konstantinos D Kokkaliaris, Oliver Hilsenbeck, Timm Schroeder, Fabian J Theis, Carsten Marr; *Nature Methods 14, 403â€“406* (2017)\n",
    "\n",
    "\n",
    "[Code](https://github.com/QSCD/HematoFatePrediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from talk_utils import tile_raster_images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct the keras network\n",
    "- Conv1\n",
    "- Conv2\n",
    "- Conv3\n",
    "- merge with speed\n",
    "- fc6\n",
    "- fc7\n",
    "- fc8/softmax\n",
    "\n",
    "![HematoCNN](images/hemato_cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talk_hemato_utils import create_hemato_cnn\n",
    "CNN = create_hemato_cnn()\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the pretrained weights onto the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe2keras_conversion\n",
    "CNN = caffe2keras_conversion.load_weights_caffe2keras('../pretrained_hemato_net.hdf5', CNN, bn_trainable=True, other_param_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the retrained weights and the corresponding data\n",
    "Turns out that the pretrained weights are hard to transfer to keras (Batch normalization etc). Hence, I retrained the network on a subset of the data provided in `images_round3_test_annotated.pickle`. \n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n",
    "\n",
    "**Note**: This is **VERY different** from the \"across-movie\" training/prediction done in the original paper.\n",
    "I instead train and evaluate on the same experiment here (samples in train/testset are still disjunct, but come from the same experiment).\n",
    "Therefore the results in this notebook are **overoptimistic**. But this notebook serves for demonstration only anyways :)\n",
    "![roundRobin](images/roundrobin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CNN.load_weights('../retrained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to get the exact same datasplit I used from training, such that our testset is different from the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../retrained_datasplit.pickle', 'rb') as fh:\n",
    "    X_train,X_val,X_test,\\\n",
    "    y_train,y_val,y_test,\\\n",
    "    mov_train, mov_val, mov_test,\\\n",
    "    cell_train, cell_val, cell_test = pickle.load(fh)\n",
    "\n",
    "print(\" %d train data\\n %d val. data\\n %d test data\" % (len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for fast computation, restrict to just 10000 test-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test   = X_test[:10000]\n",
    "y_test   = y_test[:10000]\n",
    "mov_test = mov_test[:10000]\n",
    "cell_test= cell_test[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first look at the data\n",
    "Let's look at a few examples of the two classes; \n",
    "- they look very similar to non-experts\n",
    "- sometimes differentiated cells can be observed, which are distinct (e.g. megakaryocytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_class0 = X_test[y_test[:,1]==0]\n",
    "X_class1 = X_test[y_test[:,1]==1]\n",
    "\n",
    "tile_raster_images(X_class0[:1000,:,:,0], img_dim=(1,2), \n",
    "                   tile_shape=(20,50), scale_rows_to_unit_interval=False, figsize=(20,20))\n",
    "\n",
    "tile_raster_images(X_class1[:1000,:,:,0], img_dim=(1,2), \n",
    "                   tile_shape=(20,50), scale_rows_to_unit_interval=False, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in addition we have the movement speed as a feature. Note that speed was already standardized (mean=0, std=1), hence the negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mov_test[y_test[:,1]==0], bins = np.linspace(-1,10,100), histtype='step', normed=True);\n",
    "plt.hist(mov_test[y_test[:,1]==1], bins = np.linspace(-1,10,100), histtype='step', normed=True);\n",
    "# plt.hist(mov_test[y_test[:,1]==1], 100);\n",
    "plt.xlabel('Movement speed')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.legend(['Class1', 'Class2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of annotated cells\n",
    "\n",
    "\n",
    "\n",
    "## Single image prediction\n",
    "- Predict all 10000 samples from the testset (takes ~10sec) \n",
    "- look at the histogram of the scores.\n",
    "- what is the accuracy/confusion matrix\n",
    "- what is the area under the ROC curve\n",
    "\n",
    "**Hint**: \n",
    "- the model has to inputs, the image and speed. Feed them into the model as a list\n",
    "- `sklearn.metrics` has implementations of confusion/AUC already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix\n",
    "yhat = CNN.predict([X_test, mov_test], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yhat[:,1],100);\n",
    "plt.xlabel('Prediction Score');\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(np.argmax(yhat,1), np.argmax(y_test, 1)))\n",
    "\n",
    "from talk_utils import plot_confusion_matrix\n",
    "plot_confusion_matrix(yhat,  y_test, classes=[0,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(np.argmax(y_test, 1), yhat[:,1], drop_intermediate=False)\n",
    "the_auc = auc(fpr, tpr)\n",
    "print(the_auc)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fpr, tpr, c=thresholds, cmap=plt.cm.bwr);\n",
    "plt.plot(fpr,tpr,'k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talk_hemato_utils import get_auc\n",
    "get_auc(yhat[:,1], y_test[:,1], do_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate cells over multiple timepoints\n",
    "So far, we predict a class for each single cell patch. However, through tracking, we can pool over image patches that belong to the same cell. That should make the classification more robust.\n",
    "There's a couple of ways to aggregate:\n",
    "- **hard voting**: each sample is first classified (into 0,1) and then we take the average: I.e 80% of the samples of the cell were classified as 1 -> vote for class 1 \n",
    "- **soft voting**: we could also first average the class scores of all samples of the same cell, then discretize into [0,1]\n",
    "\n",
    "- use a **neural network** to do the aggregation. [Buggenthin et al.] use a RNN to also incorporate the time dependence of the images. (We skip this for simplicity)\n",
    "\n",
    "\n",
    "**Note**: We're somewhat cheating here: The train/val/test split was agnostic of the image patches being linked together. For example, cell 1 could have 10 patches in the training set, and 20 patches in the test set -> **some leakage from training to test** if the patches are strongly correlated and our results are overoptimistic. \n",
    "\n",
    "In [Buggenthin et al.], the training/validation/testsets are **different experiments** to avoid this and similar issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellid = 353\n",
    "plt.plot(yhat[cell_test==cellid, 1]); \n",
    "plt.xlabel('image patch')\n",
    "plt.ylabel('lineage score')\n",
    "plt.title('Cell %d with true label %d' % (cellid, y_test[cell_test==cellid,1][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let pandas do the aggregation magic..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.hstack([y_test, yhat, cell_test[:,np.newaxis]]), columns=['y0', 'y1', 'score0', 'score1', 'cellid'])\n",
    "df['yhat'] = (df['score1'] > 0.5).values.astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr = df.groupby('cellid').mean()\n",
    "aggr = aggr.rename(columns={'score1': 'softvote', 'yhat': 'hardvote'}) \n",
    "aggr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to comply with the usual two column scores\n",
    "softvoted_yhat = np.vstack([1-aggr['softvote'], aggr['softvote']]).T\n",
    "hardvoted_yhat = np.vstack([1-aggr['hardvote'], aggr['hardvote']]).T\n",
    "voted_y = np.vstack([aggr['y0'], aggr['y1']]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "putting that all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_cell_scores(df):\n",
    "    \"aggregates all scores from the same cell, doing either soft or hard voting\"\n",
    "    df['yhat'] = (df['score1'] > 0.5).values.astype('int')\n",
    "    aggr = df.groupby('cellid').mean()\n",
    "    aggr = aggr.rename(columns={'score1': 'softvote1', 'yhat': 'hardvote1'})\n",
    "    aggr['softvote0'] = 1-aggr['softvote1']\n",
    "    aggr['hardvote0'] = 1-aggr['hardvote1']\n",
    "\n",
    "    return aggr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr = aggregate_cell_scores(df)\n",
    "aggr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(aggr[['softvote0', 'softvote1']].values,  aggr[['y0', 'y1']].values, classes=[0,1]);\n",
    "get_auc(aggr['softvote1'].values, aggr['y1'], do_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(aggr[['hardvote0', 'hardvote1']].values,  aggr[['y0', 'y1']].values, classes=[0,1]);\n",
    "get_auc(aggr['hardvote1'].values, aggr['y1'], do_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the CNN to \"latent\" cells\n",
    "So far, we trained the NN on cells that expressed some cell fate markers (hence they were already differentiated).\n",
    "The most important contribution of [Buggenthin et al.] is that this classifier can also be applied to cells expressing no marker yet (latent), and still correctly predict what will happen in the future (we know the future via tracking)\n",
    "\n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talk_hemato_utils import load_data\n",
    "X_l, y_l, movement_l, cellIDs_l = load_data('../images_round3_test_latent.pickle', N=None, randomize=True)\n",
    "print(\"%d patches, %d cells in total\" % (len(X_l), len(np.unique(cellIDs_l))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put the \"meta\"-data into a pandas dataframe. This will become very handy later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([y_l, cellIDs_l[:,np.newaxis]]), columns=['y0', 'y1', 'cellid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the 'inverted generation', i.e. the position of the cell wrt to marker onset in the tree. inv.gen=-2 means that the cell fate marker will turn on two generations downstream of that cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the inverted generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "mat = h5py.File('../anno_file.h5', 'r')\n",
    "gens = mat['anno']['latent'][:][0]\n",
    "gens = np.array([gens[i] for i in cellIDs_l])  # expand into a vector, one element for each patch\n",
    "df['gens'] = gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select a smaller subset of cells\n",
    "for computational reasons again, restrict to a few hundreds of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talk_hemato_utils import ismember\n",
    "\n",
    "Ncells = 200\n",
    "cell_subset = np.random.choice(np.unique(cellIDs_l), Ncells, replace=False)  # lets take 100 cells and all their patches\n",
    "subset_ix = ismember(cellIDs_l, cell_subset)\n",
    "subset_ix = np.array([_ is not None for _ in subset_ix])\n",
    "\n",
    "X_l = X_l[subset_ix]\n",
    "y_l = y_l[subset_ix]\n",
    "movement_l = movement_l[subset_ix]\n",
    "df = df.iloc[subset_ix]\n",
    "\n",
    "print(\"%d patches, %d cells in total\" % (len(X_l), len(np.unique(df['cellid']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of latent cells\n",
    "Takes 2min on a Quadcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time yhat_l = CNN.predict([X_l, movement_l], batch_size=128, verbose=1)\n",
    "\n",
    "df['score0'] = yhat_l[:,0]  # put the predictions into the dataframe\n",
    "df['score1'] = yhat_l[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "again, we want to aggregate the scores of patches belonging to the same cell.\n",
    "\n",
    "What's the distribution of patch scores for a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellid = cell_subset[0]\n",
    "df_cell = df.query(\"cellid==@cellid\")\n",
    "plt.hist(df_cell['score1'],100);\n",
    "plt.title('Cell %d (%d patches) with true label %f' % (cellid, len(df_cell),df_cell.y1.values[0]))\n",
    "plt.xlabel('lineage score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregate as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_l = aggregate_cell_scores(df)\n",
    "aggr_l.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / AUC\n",
    "Calculate the AUCs for raw patches and the aggregated cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_auc(df['score1'], df['y1'], do_plot=True)  # without aggregation\n",
    "get_auc(aggr_l['softvote1'], aggr_l['y1'], do_plot=True);\n",
    "get_auc(aggr_l['hardvote1'], aggr_l['y1'], do_plot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check how our predictive performance changes as we move further away from the observed marker onset.\n",
    "\n",
    "<img src=\"images/latent_cells.png\" alt=\"latent cells\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into the different generations relative to onset\n",
    "auc_list = []\n",
    "for g in [-5,-4,-3,-2,-1]:\n",
    "    df_g = aggr_l.query('gens==@g')\n",
    "    auc = get_auc(df_g['softvote1'], df_g['y1'])\n",
    "    auc_list.append(auc)\n",
    "\n",
    "\n",
    "plt.plot([-5,-4,-3,-2,-1], auc_list, marker='x')\n",
    "plt.xlabel('inverted generation');\n",
    "plt.ylabel('AUC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Again, keep in mind that we didnt evaluate on a totally different testset (I trained the classifier on a subset of the \"annotated\" cells in a single experiment). So applying the classifier to \"latent\" cells of the same movie might be **too optimistic** (e.g. overfitting on lighting conditions etc)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "4",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
